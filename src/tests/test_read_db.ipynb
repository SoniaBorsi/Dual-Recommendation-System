{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from src.utilities.db_utils import read_from_db\n",
    "from src.utilities.setup import load_config\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read Utility Matrix\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"2G\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load database configuration\n",
    "config = load_config(\"src/config.yaml\")\n",
    "\n",
    "# Read utility matrix from the database\n",
    "print(\"Verifying utility matrix in the database...\")\n",
    "try:\n",
    "    result_df = read_from_db(spark, config, \"SELECT * FROM utility_matrix_user_item\")\n",
    "    result_df.show(10, truncate=False)\n",
    "except Exception as e:\n",
    "    print(f\"Error reading from the database: {e}\")\n",
    "\n",
    "# Optional: Convert to Pandas for further analysis\n",
    "pandas_df = result_df.toPandas()\n",
    "print(pandas_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
