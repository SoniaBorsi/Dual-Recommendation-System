{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec0f982-68d8-4fc4-8c40-f3841a9c9ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split, udf, regexp_replace, lit, from_unixtime\n",
    "from pyspark.sql.types import ArrayType, StringType, StructType, StructField, IntegerType, StringType, MapType\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, MapType, StringType\n",
    "from pyspark.sql.functions import explode\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import split, explode, regexp_extract, col, collect_list, udf, broadcast\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, DoubleType, FloatType\n",
    "from pyspark.ml.linalg import VectorUDT, Vectors\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a502793-bc5f-4e96-a753-22bfb658195f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/12/09 14:35:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/12/09 14:35:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/12/09 14:35:44 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "# Stop existing Spark context if any\n",
    "try:\n",
    "    spark.stop()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# Reinitialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BehaviorsProcessing\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "111b3241-5686-4261-95c0-751debc6b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"  # Replace with your Java path\n",
    "os.environ[\"SPARK_HOME\"] = \"/path/to/spark\"  # Replace with your Spark installation path\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3\"  # Replace with your Python path\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"jupyter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9448e8fd-8103-4d5e-b2d8-8cdc939e959e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ImpressionID: string (nullable = true)\n",
      " |-- UserID: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- History: string (nullable = true)\n",
      " |-- Impressions: string (nullable = true)\n",
      "\n",
      "+------------+------+---------------------+--------------------------------------------------------------+-----------------+\n",
      "|ImpressionID|UserID|Time                 |History                                                       |Impressions      |\n",
      "+------------+------+---------------------+--------------------------------------------------------------+-----------------+\n",
      "|1           |U13740|11/11/2019 9:05:58 AM|N55189 N42782 N34694 N45794 N18445 N63302 N10414 N19347 N31801|N55689-1 N35729-0|\n",
      "+------------+------+---------------------+--------------------------------------------------------------+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the schema\n",
    "behaviors_schema = StructType([\n",
    "    StructField(\"ImpressionID\", StringType(), True),\n",
    "    StructField(\"UserID\", StringType(), True),\n",
    "    StructField(\"Time\", StringType(), True),\n",
    "    StructField(\"History\", StringType(), True),\n",
    "    StructField(\"Impressions\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Load the behaviors.tsv file\n",
    "behaviors_df = spark.read.csv(\n",
    "    \"data/mind/MINDsmall_train/behaviors.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    schema=behaviors_schema,\n",
    "    header=False\n",
    ")\n",
    "\n",
    "# Display the schema and a sample row\n",
    "behaviors_df.printSchema()\n",
    "behaviors_df.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3137302-b6af-48b3-922a-e71c88a1cf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+------------------------------------------------------------------------+\n",
      "|ImpressionID|UserID|HistoryList                                                             |\n",
      "+------------+------+------------------------------------------------------------------------+\n",
      "|1           |U13740|[N55189, N42782, N34694, N45794, N18445, N63302, N10414, N19347, N31801]|\n",
      "+------------+------+------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split History into an array\n",
    "behaviors_df = behaviors_df.withColumn(\"HistoryList\", split(col(\"History\"), \" \"))\n",
    "behaviors_df = behaviors_df.drop(\"History\")  # Drop original History column if not needed\n",
    "\n",
    "# Verify the transformation\n",
    "behaviors_df.select(\"ImpressionID\", \"UserID\", \"HistoryList\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50637a47-9a55-47c5-9898-deedc22f558c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|ImpressionID|ImpressionsList     |\n",
      "+------------+--------------------+\n",
      "|1           |[N55689-1, N35729-0]|\n",
      "+------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split Impressions into an array\n",
    "behaviors_df = behaviors_df.withColumn(\"ImpressionsList\", split(col(\"Impressions\"), \" \"))\n",
    "behaviors_df = behaviors_df.drop(\"Impressions\")  # Drop original Impressions column if not needed\n",
    "\n",
    "# Verify the transformation\n",
    "behaviors_df.select(\"ImpressionID\", \"ImpressionsList\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f03662b-9d9e-4055-875f-af051a5f7d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+---------------+----------+\n",
      "|ImpressionID|UserID|CandidateNewsID|ClickLabel|\n",
      "+------------+------+---------------+----------+\n",
      "|1           |U13740|N55689         |1         |\n",
      "|1           |U13740|N35729         |0         |\n",
      "|2           |U91836|N20678         |0         |\n",
      "|2           |U91836|N39317         |0         |\n",
      "|2           |U91836|N58114         |0         |\n",
      "+------------+------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explode ImpressionsList\n",
    "impressions_exploded = behaviors_df.select(\n",
    "    \"ImpressionID\",\n",
    "    \"UserID\",\n",
    "    \"Time\",\n",
    "    \"HistoryList\",\n",
    "    explode(\"ImpressionsList\").alias(\"ImpressionItem\")\n",
    ")\n",
    "\n",
    "# Extract CandidateNewsID and ClickLabel using regex\n",
    "impressions_exploded = impressions_exploded \\\n",
    "    .withColumn(\"CandidateNewsID\", regexp_extract(col(\"ImpressionItem\"), r\"^(N\\d+)-\\d+$\", 1)) \\\n",
    "    .withColumn(\"ClickLabel\", regexp_extract(col(\"ImpressionItem\"), r\"^N\\d+-(\\d+)$\", 1).cast(\"integer\")) \\\n",
    "    .drop(\"ImpressionItem\")\n",
    "\n",
    "# Verify the transformation\n",
    "impressions_exploded.select(\"ImpressionID\", \"UserID\", \"CandidateNewsID\", \"ClickLabel\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eef02ba-8117-4d3b-a442-d86f7df1406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_tfidf_path = \"news\"\n",
    "news_features_df = spark.read.parquet(news_tfidf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "244ebec2-1d16-4446-b3f5-e3e65762be40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NewsID',\n",
       " 'Category',\n",
       " 'Subcategory',\n",
       " 'Title',\n",
       " 'Abstract',\n",
       " 'URL',\n",
       " 'TitleEntities',\n",
       " 'AbstractEntities',\n",
       " 'CleanTitle',\n",
       " 'CleanAbstract',\n",
       " 'TitleTokens',\n",
       " 'AbstractTokens',\n",
       " 'FilteredTitleTokens',\n",
       " 'FilteredAbstractTokens',\n",
       " 'CombinedTokens',\n",
       " 'CombinedWords',\n",
       " 'RawFeatures',\n",
       " 'TFIDFeatures']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "809a45c8-3fdf-4859-ae0f-f2a258b1f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join impressions with news_features_df on CandidateNewsID\n",
    "impressions_with_features = impressions_exploded.join(\n",
    "    news_features_df,\n",
    "    impressions_exploded.CandidateNewsID == news_features_df.NewsID,\n",
    "    how=\"left\"\n",
    ").drop(news_features_df.NewsID)  # Drop duplicate NewsID column if present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "238ed1d5-faf6-48b4-8973-1bcc35dfa673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+---------------+----------+--------------------+--------+\n",
      "|ImpressionID|UserID|CandidateNewsID|ClickLabel|        TFIDFeatures|Category|\n",
      "+------------+------+---------------+----------+--------------------+--------+\n",
      "|           1|U13740|         N55689|         1|(10000,[8,30,51,9...|  sports|\n",
      "+------------+------+---------------+----------+--------------------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify the join\n",
    "impressions_with_features.select(\"ImpressionID\", \"UserID\", \"CandidateNewsID\", \"ClickLabel\", \"TFIDFeatures\", \"Category\").show(1, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80c87016-1cd3-4dad-b5a5-b2214b1300c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:=======>                                                   (1 + 7) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+--------------------+--------------------+---------------+----------+------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|ImpressionID|UserID|                Time|         HistoryList|CandidateNewsID|ClickLabel|    Category|     Subcategory|               Title|            Abstract|                 URL|       TitleEntities|    AbstractEntities|          CleanTitle|       CleanAbstract|         TitleTokens|      AbstractTokens| FilteredTitleTokens|FilteredAbstractTokens|      CombinedTokens|       CombinedWords|         RawFeatures|        TFIDFeatures|\n",
      "+------------+------+--------------------+--------------------+---------------+----------+------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|       20621|U21649|11/9/2019 5:15:06 PM|[N14734, N48044, ...|         N24176|         1|      health|      weightloss|Ree Drummond Says...|The Pioneer Woman...|https://assets.ms...|[{\"Label\": \"Ree D...|                  []|ree drummond says...|the pioneer woman...|[ree, drummond, s...|[the, pioneer, wo...|[ree, drummond, s...|  [pioneer, woman's...|ree drummond says...|[ree, drummond, s...|(10000,[1,15,126,...|(10000,[1,15,126,...|\n",
      "|       81980|U11232|11/10/2019 1:26:1...|[N63248, N43558, ...|         N26084|         1|foodanddrink|         recipes|These Christmas D...|We've got you cov...|https://assets.ms...|                  []|                  []|these christmas d...|we've got you cov...|[these, christmas...|[we've, got, you,...|[christmas, dinne...|  [got, covered, ty...|christmas dinner ...|[christmas, dinne...|(10000,[120,559,1...|(10000,[120,559,1...|\n",
      "|       61593|U71196|11/14/2019 10:15:...|[N25300, N11101, ...|         N32005|         1|      travel| traveltripideas|Some of the World...|You may know and ...|https://assets.ms...|                  []|                  []|some of the world...|you may know and ...|[some, of, the, w...|[you, may, know, ...|[world's, best, b...|  [may, know, love,...|world's best beac...|[world's, best, b...|(10000,[28,33,66,...|(10000,[28,33,66,...|\n",
      "|      102498|U68128|11/13/2019 12:56:...|[N34930, N50, N46...|          N4247|         1|      health|       nutrition|The keto diet is ...|Let's face it: He...|https://assets.ms...|                  []|                  []|the keto diet is ...|let's face it: he...|[the, keto, diet,...|[let's, face, it:...|[keto, diet, hard...|  [face, it:, healt...|keto diet hard wo...|[keto, diet, hard...|(10000,[0,136,184...|(10000,[0,136,184...|\n",
      "|      143656|U74335|11/11/2019 3:07:0...|[N13008, N19593, ...|         N50059|         1|       autos|autosenthusiasts|This Ford GT40 Mo...|It's half Ford GT...|https://assets.ms...|[{\"Label\": \"Ford ...|[{\"Label\": \"Ford ...|this ford gt40 mo...|it's half ford gt...|[this, ford, gt40...|[it's, half, ford...|[ford, gt40, movi...|  [half, ford, gt40...|ford gt40 movie r...|[ford, gt40, movi...|(10000,[79,300,40...|(10000,[79,300,40...|\n",
      "+------------+------+--------------------+--------------------+---------------+----------+------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Filter records where ClickLabel == 1\n",
    "clicked_news_df = impressions_with_features.filter(col(\"ClickLabel\") == 1)\n",
    "\n",
    "# Verify the filtered DataFrame\n",
    "clicked_news_df.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eb62de2-2179-4ca1-a57a-bda89fbef94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "# Define a function to compute cosine similarity\n",
    "def cosine_similarity_udf(u_vec, i_vec):\n",
    "    if u_vec is None or i_vec is None:\n",
    "        return 0.0\n",
    "    u_arr = u_vec.toArray()\n",
    "    i_arr = i_vec.toArray()\n",
    "    norm_u = np.linalg.norm(u_arr)\n",
    "    norm_i = np.linalg.norm(i_arr)\n",
    "    if norm_u == 0 or norm_i == 0:  # Avoid division by zero\n",
    "        return 0.0\n",
    "    return float(np.dot(u_arr, i_arr) / (norm_u * norm_i))\n",
    "\n",
    "# Register the UDF\n",
    "cosine_udf = udf(cosine_similarity_udf, FloatType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986b7906-a1cb-4552-9971-9aa1e19a30fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2434a104-0ad9-469a-bce7-1348a7459e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "\n",
    "# Define a UDF to average vectors\n",
    "def average_vectors(vectors, count):\n",
    "    if count == 0 or not vectors:  # Avoid division by zero or empty vectors\n",
    "        return Vectors.dense([0.0] * len(vectors[0].toArray())) if vectors else Vectors.dense([0.0])\n",
    "    summed_vector = [sum(component) for component in zip(*[v.toArray() for v in vectors])]\n",
    "    averaged_vector = [component / count for component in summed_vector]\n",
    "    return Vectors.dense(averaged_vector)\n",
    "\n",
    "avg_vector_udf = udf(average_vectors, VectorUDT())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "974faeb2-124d-4332-aea8-890c1de0c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Build category-specific user profiles\n",
    "category_user_profiles = clicked_news_df.groupBy(\"UserID\", \"Category\").agg(\n",
    "    F.collect_list(\"TFIDFeatures\").alias(\"UserVectors\"),\n",
    "    F.size(F.collect_list(\"TFIDFeatures\")).alias(\"CountVectors\")\n",
    ").withColumn(\n",
    "    \"UserProfile\",\n",
    "    avg_vector_udf(\"UserVectors\", \"CountVectors\")\n",
    ").drop(\"UserVectors\", \"CountVectors\")\n",
    "\n",
    "# Join news data with user profiles to ensure category alignment\n",
    "user_recs_with_category = category_user_profiles.join(\n",
    "    news_features_df,  # news DataFrame with category information\n",
    "    on=\"Category\",  # Match articles with user preferences in the same category\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e877a59-cb96-40d8-9452-b305453e4089",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# If a session was running\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      3\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder \\\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommenderSystem\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.driver.memory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4g\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.executor.memory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4g\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mgetOrCreate()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/session.py:1113\u001b[0m, in \u001b[0;36mSparkSession.stop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Stop the underlying :class:`SparkContext`.\"\"\"\u001b[39;00m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SQLContext\n\u001b[0;32m-> 1113\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# We should clean the default session up. See SPARK-23228.\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/context.py:558\u001b[0m, in \u001b[0;36mSparkContext.stop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_jsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 558\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JError:\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;66;03m# Case: SPARK-18523\u001b[39;00m\n\u001b[1;32m    561\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    562\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to cleanly shutdown Spark JVM process.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m It is possible that the process has crashed,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    564\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m been killed or may also be in a zombie state.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    565\u001b[0m             \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[1;32m    566\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "spark.stop()  # If a session was running\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RecommenderSystem\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55208754-3bd8-4570-9416-2706973fb627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o263.showString",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m top_n_recs \u001b[38;5;241m=\u001b[39m user_recs_with_category\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m\"\u001b[39m, F\u001b[38;5;241m.\u001b[39mrow_number()\u001b[38;5;241m.\u001b[39mover(windowSpec)) \\\n\u001b[1;32m     18\u001b[0m                                     \u001b[38;5;241m.\u001b[39mfilter(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# Top-5 recommendations per category\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mtop_n_recs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUserID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCategory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNewsID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msimilarity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrank\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/dataframe.py:615\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncate=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be either bool or int.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(truncate)\n\u001b[1;32m    613\u001b[0m     )\n\u001b[0;32m--> 615\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mint_truncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    192\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o263.showString"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    }
   ],
   "source": [
    "# Compute similarity scores\n",
    "def cosine_similarity(u_vec, i_vec):\n",
    "    u_arr = u_vec.toArray()\n",
    "    i_arr = i_vec.toArray()\n",
    "    similarity = np.dot(u_arr, i_arr) / (np.linalg.norm(u_arr) * np.linalg.norm(i_arr))\n",
    "    return float(similarity)\n",
    "\n",
    "cosine_udf = udf(cosine_similarity, FloatType())\n",
    "\n",
    "user_recs_with_category = user_recs_with_category.withColumn(\n",
    "    \"similarity\",\n",
    "    cosine_udf(F.col(\"UserProfile\"), F.col(\"TFIDFeatures\"))\n",
    ")\n",
    "\n",
    "# Rank and select top recommendations\n",
    "windowSpec = Window.partitionBy(\"UserID\", \"Category\").orderBy(F.desc(\"similarity\"))\n",
    "top_n_recs = user_recs_with_category.withColumn(\"rank\", F.row_number().over(windowSpec)) \\\n",
    "                                    .filter(F.col(\"rank\") <= 5)  # Top-5 recommendations per category\n",
    "\n",
    "# Display results\n",
    "top_n_recs.select(\"UserID\", \"Category\", \"NewsID\", \"similarity\", \"rank\").show(10, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
