{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aec0f982-68d8-4fc4-8c40-f3841a9c9ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split, udf, regexp_replace, lit, from_unixtime\n",
    "from pyspark.sql.types import ArrayType, StringType, StructType, StructField, IntegerType, StringType, MapType\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, MapType, StringType\n",
    "from pyspark.sql.functions import explode\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import split, explode, regexp_extract, col, collect_list, udf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, DoubleType\n",
    "from pyspark.ml.linalg import VectorUDT, Vectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a502793-bc5f-4e96-a753-22bfb658195f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/12/07 16:07:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/12/07 16:07:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/12/07 16:07:16 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 58962)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.9/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.9/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.9/socketserver.py\", line 720, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pyspark/accumulators.py\", line 281, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pyspark/accumulators.py\", line 253, in poll\n",
      "    if func():\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pyspark/accumulators.py\", line 257, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pyspark/serializers.py\", line 595, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"BehaviorsProcessing\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9448e8fd-8103-4d5e-b2d8-8cdc939e959e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ImpressionID: string (nullable = true)\n",
      " |-- UserID: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- History: string (nullable = true)\n",
      " |-- Impressions: string (nullable = true)\n",
      "\n",
      "+------------+------+---------------------+--------------------------------------------------------------+-----------------+\n",
      "|ImpressionID|UserID|Time                 |History                                                       |Impressions      |\n",
      "+------------+------+---------------------+--------------------------------------------------------------+-----------------+\n",
      "|1           |U13740|11/11/2019 9:05:58 AM|N55189 N42782 N34694 N45794 N18445 N63302 N10414 N19347 N31801|N55689-1 N35729-0|\n",
      "+------------+------+---------------------+--------------------------------------------------------------+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Define the schema\n",
    "behaviors_schema = StructType([\n",
    "    StructField(\"ImpressionID\", StringType(), True),\n",
    "    StructField(\"UserID\", StringType(), True),\n",
    "    StructField(\"Time\", StringType(), True),\n",
    "    StructField(\"History\", StringType(), True),\n",
    "    StructField(\"Impressions\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Load the behaviors.tsv file\n",
    "behaviors_df = spark.read.csv(\n",
    "    \"data/mind/MINDsmall_train/behaviors.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    schema=behaviors_schema,\n",
    "    header=False\n",
    ")\n",
    "\n",
    "# Display the schema and a sample row\n",
    "behaviors_df.printSchema()\n",
    "behaviors_df.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3137302-b6af-48b3-922a-e71c88a1cf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+------------------------------------------------------------------------+\n",
      "|ImpressionID|UserID|HistoryList                                                             |\n",
      "+------------+------+------------------------------------------------------------------------+\n",
      "|1           |U13740|[N55189, N42782, N34694, N45794, N18445, N63302, N10414, N19347, N31801]|\n",
      "+------------+------+------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split History into an array\n",
    "behaviors_df = behaviors_df.withColumn(\"HistoryList\", split(col(\"History\"), \" \"))\n",
    "behaviors_df = behaviors_df.drop(\"History\")  # Drop original History column if not needed\n",
    "\n",
    "# Verify the transformation\n",
    "behaviors_df.select(\"ImpressionID\", \"UserID\", \"HistoryList\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50637a47-9a55-47c5-9898-deedc22f558c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|ImpressionID|ImpressionsList     |\n",
      "+------------+--------------------+\n",
      "|1           |[N55689-1, N35729-0]|\n",
      "+------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split Impressions into an array\n",
    "behaviors_df = behaviors_df.withColumn(\"ImpressionsList\", split(col(\"Impressions\"), \" \"))\n",
    "behaviors_df = behaviors_df.drop(\"Impressions\")  # Drop original Impressions column if not needed\n",
    "\n",
    "# Verify the transformation\n",
    "behaviors_df.select(\"ImpressionID\", \"ImpressionsList\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f03662b-9d9e-4055-875f-af051a5f7d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+---------------+----------+\n",
      "|ImpressionID|UserID|CandidateNewsID|ClickLabel|\n",
      "+------------+------+---------------+----------+\n",
      "|1           |U13740|N55689         |1         |\n",
      "|1           |U13740|N35729         |0         |\n",
      "|2           |U91836|N20678         |0         |\n",
      "|2           |U91836|N39317         |0         |\n",
      "|2           |U91836|N58114         |0         |\n",
      "+------------+------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explode ImpressionsList\n",
    "impressions_exploded = behaviors_df.select(\n",
    "    \"ImpressionID\",\n",
    "    \"UserID\",\n",
    "    \"Time\",\n",
    "    \"HistoryList\",\n",
    "    explode(\"ImpressionsList\").alias(\"ImpressionItem\")\n",
    ")\n",
    "\n",
    "# Extract CandidateNewsID and ClickLabel using regex\n",
    "impressions_exploded = impressions_exploded \\\n",
    "    .withColumn(\"CandidateNewsID\", regexp_extract(col(\"ImpressionItem\"), r\"^(N\\d+)-\\d+$\", 1)) \\\n",
    "    .withColumn(\"ClickLabel\", regexp_extract(col(\"ImpressionItem\"), r\"^N\\d+-(\\d+)$\", 1).cast(\"integer\")) \\\n",
    "    .drop(\"ImpressionItem\")\n",
    "\n",
    "# Verify the transformation\n",
    "impressions_exploded.select(\"ImpressionID\", \"UserID\", \"CandidateNewsID\", \"ClickLabel\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eef02ba-8117-4d3b-a442-d86f7df1406f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "news_tfidf_path = \"news_tfidf.parquet\"\n",
    "news_features_df = spark.read.parquet(news_tfidf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "244ebec2-1d16-4446-b3f5-e3e65762be40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|NewsID|       TFIDFFeatures|\n",
      "+------+--------------------+\n",
      "| N5727|(10000,[1,9,87,90...|\n",
      "|N25908|(10000,[165,280,4...|\n",
      "| N2490|(10000,[1,218,262...|\n",
      "|  N192|(10000,[71,2006,2...|\n",
      "| N1298|(10000,[3,26,42,4...|\n",
      "|N57313|(10000,[36,61,109...|\n",
      "|N36185|(10000,[6,21,74,8...|\n",
      "|N33743|(10000,[2,13,16,3...|\n",
      "|N58255|(10000,[0,10,14,3...|\n",
      "|N44291|(10000,[0,4,15,84...|\n",
      "|N38233|(10000,[5,7,11,69...|\n",
      "| N1970|(10000,[4,26,30,3...|\n",
      "|N41692|(10000,[4,12,31,1...|\n",
      "|N31209|(10000,[4,34,59,1...|\n",
      "|N60452|(10000,[154,159,2...|\n",
      "|N22043|(10000,[36,119,25...|\n",
      "|N30368|(10000,[45,815,12...|\n",
      "| N4233|(10000,[11,90,121...|\n",
      "|N51387|(10000,[111,865,1...|\n",
      "|N22126|(10000,[4,18,34,3...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "news_features_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "809a45c8-3fdf-4859-ae0f-f2a258b1f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join impressions with news_features_df on CandidateNewsID\n",
    "impressions_with_features = impressions_exploded.join(\n",
    "    news_features_df,\n",
    "    impressions_exploded.CandidateNewsID == news_features_df.NewsID,\n",
    "    how=\"left\"\n",
    ").drop(news_features_df.NewsID)  # Drop duplicate NewsID column if present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "238ed1d5-faf6-48b4-8973-1bcc35dfa673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+---------------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ImpressionID|UserID|CandidateNewsID|ClickLabel|TFIDFFeatures                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "+------------+------+---------------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1           |U13740|N55689         |1         |(10000,[8,30,51,90,94,156,171,203,334,570,641,1139,1431,1736,2792,3053,3095,4218,9542],[5.764478100579534,6.580188170160226,7.286765598126918,3.752068193101451,3.911344460777521,9.037703072834718,4.2392206559289365,8.495633394797467,9.595534231313914,10.292563290640578,4.998714934579382,5.582242390122105,11.728949715612643,5.80129595618479,6.2919188726332616,6.529048665922211,13.7198058204784,6.8599029102392,7.747206105240103])|\n",
      "+------------+------+---------------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify the join\n",
    "impressions_with_features.select(\"ImpressionID\", \"UserID\", \"CandidateNewsID\", \"ClickLabel\", \"TFIDFFeatures\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80c87016-1cd3-4dad-b5a5-b2214b1300c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+--------------------+--------------------+---------------+----------+--------------------+\n",
      "|ImpressionID|UserID|                Time|         HistoryList|CandidateNewsID|ClickLabel|       TFIDFFeatures|\n",
      "+------------+------+--------------------+--------------------+---------------+----------+--------------------+\n",
      "|           1|U13740|11/11/2019 9:05:5...|[N55189, N42782, ...|         N55689|         1|(10000,[8,30,51,9...|\n",
      "|           2|U91836|11/12/2019 6:11:3...|[N31739, N6072, N...|         N17059|         1|(10000,[25,38,108...|\n",
      "|           3|U73700|11/14/2019 7:01:4...|[N10732, N25792, ...|         N23814|         1|(10000,[43,100,14...|\n",
      "|           4|U34670|11/11/2019 5:28:0...|[N45729, N2203, N...|         N49685|         1|(10000,[128,170,2...|\n",
      "|           5| U8125|11/12/2019 4:11:2...|[N10078, N56514, ...|          N8400|         1|(10000,[1,63,79,1...|\n",
      "+------------+------+--------------------+--------------------+---------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter records where ClickLabel == 1\n",
    "clicked_news_df = impressions_with_features.filter(col(\"ClickLabel\") == 1)\n",
    "\n",
    "# Verify the filtered DataFrame\n",
    "clicked_news_df.show(5, truncate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdbcc3bb-3d79-4187-91ff-86a534840369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 8) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|UserID|    ClickedTFIDFList|\n",
      "+------+--------------------+\n",
      "|U10022|[(10000,[37,152,1...|\n",
      "+------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Group by UserID and collect all TFIDFFeatures into a list\n",
    "user_clicks_df = clicked_news_df.groupBy(\"UserID\") \\\n",
    "    .agg(collect_list(\"TFIDFFeatures\").alias(\"ClickedTFIDFList\"))\n",
    "\n",
    "# Verify the aggregation\n",
    "user_clicks_df.show(1, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2821808c-d9b7-4bd0-94a8-ac497973dbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|UserID|         UserProfile|\n",
      "+------+--------------------+\n",
      "|U10022|[0.53004950030122...|\n",
      "+------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.linalg import VectorUDT, DenseVector\n",
    "\n",
    "# Define the UDF to compute average vector\n",
    "def average_vector(vectors):\n",
    "    if not vectors:\n",
    "        return Vectors.sparse(10000, [])  # Adjust size if different\n",
    "    sum_array = np.sum([v.toArray() for v in vectors], axis=0)\n",
    "    mean_array = sum_array / len(vectors)\n",
    "    return Vectors.dense(mean_array)\n",
    "\n",
    "# Register the UDF\n",
    "average_vector_udf = udf(average_vector, VectorUDT())\n",
    "\n",
    "# Apply the UDF to create UserProfile\n",
    "user_profiles_df = user_clicks_df.withColumn(\"UserProfile\", average_vector_udf(col(\"ClickedTFIDFList\"))) \\\n",
    "    .select(\"UserID\", \"UserProfile\")\n",
    "\n",
    "# Verify the user profiles\n",
    "user_profiles_df.show(1, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6a5d291-e0c1-4407-b132-75b39b62f6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+---------------+----------+\n",
      "|ImpressionID|UserID|CandidateNewsID|ClickLabel|\n",
      "+------------+------+---------------+----------+\n",
      "|1           |U13740|N55689         |1         |\n",
      "|1           |U13740|N35729         |0         |\n",
      "|2           |U91836|N20678         |0         |\n",
      "|2           |U91836|N39317         |0         |\n",
      "|2           |U91836|N58114         |0         |\n",
      "+------------+------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------+------+------------------------------------------------------------------------+--------------------+\n",
      "|ImpressionID|UserID|HistoryList                                                             |ImpressionsList     |\n",
      "+------------+------+------------------------------------------------------------------------+--------------------+\n",
      "|1           |U13740|[N55189, N42782, N34694, N45794, N18445, N63302, N10414, N19347, N31801]|[N55689-1, N35729-0]|\n",
      "+------------+------+------------------------------------------------------------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, regexp_extract\n",
    "\n",
    "# Explode the 'ImpressionsList' into individual 'ImpressionItem' rows\n",
    "impressions_exploded = behaviors_df.select(\n",
    "    \"ImpressionID\",\n",
    "    \"UserID\",\n",
    "    \"HistoryList\",\n",
    "    explode(\"ImpressionsList\").alias(\"ImpressionItem\")\n",
    ")\n",
    "\n",
    "# Extract 'CandidateNewsID' and 'ClickLabel' using regex\n",
    "impressions_exploded = impressions_exploded \\\n",
    "    .withColumn(\"CandidateNewsID\", regexp_extract(col(\"ImpressionItem\"), r\"^(N\\d+)-\\d+$\", 1)) \\\n",
    "    .withColumn(\"ClickLabel\", regexp_extract(col(\"ImpressionItem\"), r\"^N\\d+-(\\d+)$\", 1).cast(\"integer\")) \\\n",
    "    .drop(\"ImpressionItem\")\n",
    "\n",
    "# Verify the transformation\n",
    "impressions_exploded.select(\"ImpressionID\", \"UserID\", \"CandidateNewsID\", \"ClickLabel\").show(5, truncate=False)\n",
    "behaviors_df.select(\"ImpressionID\", \"UserID\", \"HistoryList\", \"ImpressionsList\").show(1, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ccca624-0b46-4e55-be19-dd657fe9a967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+---------------+----------+\n",
      "|ImpressionID|UserID|CandidateNewsID|ClickLabel|\n",
      "+------------+------+---------------+----------+\n",
      "|1           |U13740|N55689         |1         |\n",
      "|1           |U13740|N35729         |0         |\n",
      "|2           |U91836|N20678         |0         |\n",
      "|2           |U91836|N39317         |0         |\n",
      "|2           |U91836|N58114         |0         |\n",
      "+------------+------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, regexp_extract\n",
    "\n",
    "# Explode the 'ImpressionsList' into individual 'ImpressionItem' rows\n",
    "impressions_exploded = behaviors_df.select(\n",
    "    \"ImpressionID\",\n",
    "    \"UserID\",\n",
    "    \"HistoryList\",\n",
    "    explode(\"ImpressionsList\").alias(\"ImpressionItem\")\n",
    ")\n",
    "\n",
    "# Extract 'CandidateNewsID' and 'ClickLabel' using regex\n",
    "impressions_exploded = impressions_exploded \\\n",
    "    .withColumn(\"CandidateNewsID\", regexp_extract(col(\"ImpressionItem\"), r\"^(N\\d+)-\\d+$\", 1)) \\\n",
    "    .withColumn(\"ClickLabel\", regexp_extract(col(\"ImpressionItem\"), r\"^N\\d+-(\\d+)$\", 1).cast(\"integer\")) \\\n",
    "    .drop(\"ImpressionItem\")\n",
    "\n",
    "# Verify the transformation\n",
    "impressions_exploded.select(\"ImpressionID\", \"UserID\", \"CandidateNewsID\", \"ClickLabel\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63f7c66f-80d5-43cd-8248-bd49b41f1deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+---------------+----------+--------------------+\n",
      "|ImpressionID|UserID|CandidateNewsID|ClickLabel|       TFIDFFeatures|\n",
      "+------------+------+---------------+----------+--------------------+\n",
      "|           1|U13740|         N55689|         1|(10000,[8,30,51,9...|\n",
      "|           1|U13740|         N35729|         0|(10000,[1,56,90,9...|\n",
      "|           2|U91836|         N20678|         0|(10000,[21,44,82,...|\n",
      "|           2|U91836|         N39317|         0|(10000,[8,10,16,2...|\n",
      "|           2|U91836|         N58114|         0|                null|\n",
      "+------------+------+---------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "impressions_with_features = impressions_exploded.join(\n",
    "    news_features_df,\n",
    "    impressions_exploded.CandidateNewsID == news_features_df.NewsID,\n",
    "    how=\"left\"\n",
    ").drop(news_features_df.NewsID)  # Remove duplicate 'NewsID' column if present\n",
    "\n",
    "# Verify the join\n",
    "impressions_with_features.select(\"ImpressionID\", \"UserID\", \"CandidateNewsID\", \"ClickLabel\", \"TFIDFFeatures\").show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a6ec9b1-1bf9-460f-b1f0-8a4a952091aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|UserID|PastNewsID|\n",
      "+------+----------+\n",
      "|U13740|N55189    |\n",
      "|U13740|N42782    |\n",
      "|U13740|N34694    |\n",
      "|U13740|N45794    |\n",
      "|U13740|N18445    |\n",
      "+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "# Explode the 'HistoryList' to get individual 'PastNewsID's\n",
    "user_history_exploded = behaviors_df.select(\n",
    "    \"UserID\",\n",
    "    explode(\"HistoryList\").alias(\"PastNewsID\")\n",
    ")\n",
    "\n",
    "# Verify the exploded history\n",
    "user_history_exploded.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d813ee4-1f17-4f41-83a0-a2f213a09315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------------+\n",
      "|UserID|PastNewsID|       TFIDFFeatures|\n",
      "+------+----------+--------------------+\n",
      "|U13740|    N55189|(10000,[1,5,11,22...|\n",
      "|U13740|    N42782|(10000,[13,18,37,...|\n",
      "|U13740|    N34694|(10000,[154,2065,...|\n",
      "|U13740|    N45794|(10000,[4,34,52,1...|\n",
      "|U13740|    N18445|(10000,[34,102,15...|\n",
      "+------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join with news_features_df to get TFIDFFeatures for past clicked news\n",
    "user_history_with_features = user_history_exploded.join(\n",
    "    news_features_df,\n",
    "    user_history_exploded.PastNewsID == news_features_df.NewsID,\n",
    "    how=\"left\"\n",
    ").drop(news_features_df.NewsID)\n",
    "\n",
    "# Verify the join\n",
    "user_history_with_features.select(\"UserID\", \"PastNewsID\", \"TFIDFFeatures\").show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9c9733e-6ce3-4157-babd-8cdc4b590826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/12/07 16:08:24 WARN PythonUDFRunner: Detected deadlock while completing task 0.0 in stage 29 (TID 96): Attempting to kill Python Worker\n",
      "+------+--------------------+\n",
      "|UserID|         UserProfile|\n",
      "+------+--------------------+\n",
      "|U10022|[0.44170791691768...|\n",
      "+------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_list, udf\n",
    "from pyspark.ml.linalg import VectorUDT, Vectors\n",
    "import numpy as np\n",
    "\n",
    "# Define a UDF to compute the average vector\n",
    "def average_vectors(vectors):\n",
    "    if not vectors:\n",
    "        return Vectors.sparse(10000, [])  # Adjust size if different\n",
    "    sum_array = np.sum([v.toArray() for v in vectors], axis=0)\n",
    "    mean_array = sum_array / len(vectors)\n",
    "    return Vectors.dense(mean_array)\n",
    "\n",
    "average_vectors_udf = udf(average_vectors, VectorUDT())\n",
    "\n",
    "# Group by UserID and collect all TFIDFFeatures into a list\n",
    "user_profiles = user_history_with_features.groupBy(\"UserID\") \\\n",
    "    .agg(collect_list(\"TFIDFFeatures\").alias(\"ClickedTFIDFList\")) \\\n",
    "    .withColumn(\"UserProfile\", average_vectors_udf(col(\"ClickedTFIDFList\"))) \\\n",
    "    .select(\"UserID\", \"UserProfile\")\n",
    "\n",
    "# Verify the user profiles\n",
    "user_profiles.show(1, truncate=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
